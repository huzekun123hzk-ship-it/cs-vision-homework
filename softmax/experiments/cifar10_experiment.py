"""
CIFAR-10 Softmaxåˆ†ç±»å™¨å®éªŒ

å®Œæ•´çš„å®éªŒæµç¨‹ï¼š
1. åŠ è½½CIFAR-10æ•°æ®é›†
2. æ•°æ®é¢„å¤„ç†
3. è®­ç»ƒSoftmaxåˆ†ç±»å™¨
4. è¯„ä¼°æ¨¡å‹æ€§èƒ½
5. ç”Ÿæˆå¯è§†åŒ–ç»“æœ
"""

import sys
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import numpy as np
import matplotlib.pyplot as plt
from softmax_classifier import SoftmaxClassifier
from cifar10_utils import load_cifar10, preprocess_data, get_cifar10_class_names


# ============================================================================
# å®éªŒé…ç½® - åœ¨è¿™é‡Œä¿®æ”¹æ‰€æœ‰è¶…å‚æ•°
# ============================================================================
CONFIG = {
    # æ•°æ®é›†é…ç½®
    'data': {
        'train_samples': 49000,
        'val_samples': 1000,
        'test_samples': 1000,
    },
    
    # æ¨¡å‹é…ç½®
    'model': {
        'reg_strength': 5e-4,  # L2æ­£åˆ™åŒ–å¼ºåº¦
    },
    
    # è®­ç»ƒé…ç½®
    'training': {
        'learning_rate': 0.005,      # åˆå§‹å­¦ä¹ ç‡
        'num_epochs': 1000,           # æœ€å¤§è®­ç»ƒè½®æ•°
        'batch_size': 128,           # æ‰¹æ¬¡å¤§å°
        'patience': 200,             # æ—©åœè€å¿ƒå€¼
        'print_every': 20,           # æ‰“å°é—´éš”
        'lr_decay_epochs': 150,       # å­¦ä¹ ç‡è¡°å‡é—´éš”
        'lr_decay_rate': 0.99,       # å­¦ä¹ ç‡è¡°å‡ç‡
    },
    
    # å¯è§†åŒ–é…ç½®
    'visualization': {
        'num_pred_samples': 20,      # é¢„æµ‹å¯è§†åŒ–æ ·æœ¬æ•°
    }
}
# ============================================================================


def visualize_weights(W, class_names, save_path):
    """å¯è§†åŒ–å­¦ä¹ åˆ°çš„æƒé‡æ¨¡æ¿"""
    fig, axes = plt.subplots(2, 5, figsize=(12, 6))
    axes = axes.flatten()
    
    for i in range(10):
        w = W[:3072, i].reshape(32, 32, 3)
        w_normalized = (w - w.min()) / (w.max() - w.min())
        
        axes[i].imshow(w_normalized)
        axes[i].set_title(class_names[i], fontsize=11, fontweight='bold')
        axes[i].axis('off')
    
    plt.suptitle('Learned Weight Templates for Each Class', 
                 fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ“ æƒé‡å¯è§†åŒ–å·²ä¿å­˜: {save_path.name}")


def plot_training_curves(history, save_path):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    epochs = history['epochs']
    
    # æŸå¤±æ›²çº¿ - è½¬æ¢å­—å…¸ä¸ºåˆ—è¡¨
    loss_epochs = sorted(history['loss_history'].keys())
    loss_values = [history['loss_history'][e] for e in loss_epochs]
    
    ax1.plot(loss_values, 'b-', linewidth=2, alpha=0.8)
    ax1.set_xlabel('Iteration', fontsize=12)
    ax1.set_ylabel('Loss', fontsize=12)
    ax1.set_title('Training Loss over Time', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.set_xlim(0, len(loss_values))
    
    # å‡†ç¡®ç‡æ›²çº¿
    ax2.plot(epochs, history['train_acc_history'], 'b-', 
             label='Training Accuracy', linewidth=2, alpha=0.8)
    ax2.plot(epochs, history['val_acc_history'], 'r-', 
             label='Validation Accuracy', linewidth=2, alpha=0.8)
    ax2.set_xlabel('Epoch', fontsize=12)
    ax2.set_ylabel('Accuracy', fontsize=12)
    ax2.set_title('Training & Validation Accuracy', fontsize=14, fontweight='bold')
    ax2.legend(fontsize=11, loc='lower right')
    ax2.grid(True, alpha=0.3)
    ax2.set_xlim(0, max(epochs))
    ax2.set_ylim(0, 1)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()

def visualize_predictions(X_test, y_test, classifier, class_names, save_path, num_samples=20):
    """å¯è§†åŒ–æ¨¡å‹é¢„æµ‹ç»“æœ"""
    indices = np.random.choice(len(X_test), num_samples, replace=False)
    
    fig, axes = plt.subplots(4, 5, figsize=(15, 12))
    axes = axes.flatten()
        
    for idx, ax in enumerate(axes):
        i = indices[idx]
        img = X_test[i, :3072].reshape(32, 32, 3)
        img = (img - img.min()) / (img.max() - img.min() + 1e-5)
        img = np.clip(img, 0, 1)
        
        pred = classifier.predict(X_test[i:i+1])[0]
        true = y_test[i]
        
        ax.imshow(img)
        color = 'green' if pred == true else 'red'
        
        ax.set_title(f'True: {class_names[true]}Pred: {class_names[pred]}',
            color=color, fontsize=10, fontweight='bold')

        ax.axis('off')
    
    plt.suptitle('Sample Predictions (Green=Correct, Red=Wrong)', 
                 fontsize=14, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ“ é¢„æµ‹å¯è§†åŒ–å·²ä¿å­˜: {save_path.name}")


def print_config():
    """æ‰“å°å½“å‰é…ç½®"""
    print("" + "=" * 70)
    print("å®éªŒé…ç½®:")
    print("=" * 70)
    
    print("ğŸ“Š æ•°æ®é›†:")
    for key, value in CONFIG['data'].items():
        print(f"  â€¢ {key}: {value}")
    
    print("ğŸ§  æ¨¡å‹:")
    for key, value in CONFIG['model'].items():
        print(f"  â€¢ {key}: {value}")
    
    print("ğŸ¯ è®­ç»ƒ:")
    for key, value in CONFIG['training'].items():
        print(f"  â€¢ {key}: {value}")
    
    print("ğŸ¨ å¯è§†åŒ–:")
    for key, value in CONFIG['visualization'].items():
        print(f"  â€¢ {key}: {value}")
    
    print("=" * 70)


def main():
    """ä¸»å®éªŒæµç¨‹"""
    print("=" * 70)
    print(" " * 15 + "CIFAR-10 Softmaxåˆ†ç±»å™¨å®éªŒ")
    print("=" * 70)
    
    # æ‰“å°é…ç½®
    print_config()
    
    # è®¾ç½®ç»“æœç›®å½•
    results_dir = Path(__file__).parent / 'cifar10_results'
    results_dir.mkdir(exist_ok=True)
    
    # ==================== 1. åŠ è½½æ•°æ® ====================
    print("[1/6] åŠ è½½CIFAR-10æ•°æ®é›†...")
    print("-" * 70)
    X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10(
        data_dir='../../data/cifar-10-batches-py',
        train_samples=CONFIG['data']['train_samples'],
        val_samples=CONFIG['data']['val_samples'],
        test_samples=CONFIG['data']['test_samples']
    )
    print(f"âœ“ è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
    print(f"âœ“ éªŒè¯é›†: {len(X_val)} æ ·æœ¬")
    print(f"âœ“ æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
    print(f"âœ“ å›¾åƒå°ºå¯¸: {X_train.shape[1:]}")
    
    # ==================== 2. é¢„å¤„ç† ====================
    print("[2/6] æ•°æ®é¢„å¤„ç†...")
    print("-" * 70)
    X_train, X_val, X_test = preprocess_data(X_train, X_val, X_test)
    print(f"âœ“ å±•å¹³åç‰¹å¾ç»´åº¦: {X_train.shape[1]} (3072åƒç´  + 1åç½®)")
    print(f"âœ“ æ•°æ®å·²ä¸­å¿ƒåŒ–ï¼ˆå‡å»è®­ç»ƒé›†å‡å€¼ï¼‰")
    print(f"âœ“ å·²æ·»åŠ åç½®é¡¹")
    
    # ==================== 3. åˆ›å»ºåˆ†ç±»å™¨ ====================
    print("[3/6] åˆ›å»ºSoftmaxåˆ†ç±»å™¨...")
    print("-" * 70)
    classifier = SoftmaxClassifier(
        num_features=X_train.shape[1],
        num_classes=10,
        reg_strength=CONFIG['model']['reg_strength']
    )
    print(f"âœ“ è¾“å…¥ç‰¹å¾æ•°: {classifier.num_features}")
    print(f"âœ“ è¾“å‡ºç±»åˆ«æ•°: {classifier.num_classes}")
    print(f"âœ“ æƒé‡å‚æ•°é‡: {classifier.W.size:,}")
    print(f"âœ“ æ­£åˆ™åŒ–å¼ºåº¦: {classifier.reg_strength}")
    
    # ==================== 4. è®­ç»ƒ ====================
    print("[4/6] å¼€å§‹è®­ç»ƒ...")
    print("=" * 70)
    
    history = classifier.train(
        X_train, y_train,
        X_val, y_val,
        learning_rate=CONFIG['training']['learning_rate'],
        num_epochs=CONFIG['training']['num_epochs'],
        batch_size=CONFIG['training']['batch_size'],
        patience=CONFIG['training']['patience'],
        verbose=True,
        print_every=CONFIG['training']['print_every']
    )
    
    # ==================== 5. è¯„ä¼° ====================
    print("[5/6] è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    print("=" * 70)
    train_acc = classifier.evaluate(X_train, y_train)
    val_acc = classifier.evaluate(X_val, y_val)
    test_acc = classifier.evaluate(X_test, y_test)
    
    print(f"è®­ç»ƒé›†å‡†ç¡®ç‡: {train_acc:.4f} ({train_acc*100:.2f}%)")
    print(f"éªŒè¯é›†å‡†ç¡®ç‡: {val_acc:.4f} ({val_acc*100:.2f}%)")
    print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.4f} ({test_acc*100:.2f}%)")
    print("=" * 70)
    
    # ==================== 6. ä¿å­˜ç»“æœ ====================
    print("[6/6] ä¿å­˜å®éªŒç»“æœ...")
    print("-" * 70)
    
    # 6.1 ä¿å­˜æ¨¡å‹æƒé‡
    model_path = results_dir / 'softmax_classifier.npy'
    classifier.save_model(str(model_path))
    print(f"âœ“ æ¨¡å‹æƒé‡å·²ä¿å­˜: {model_path.name}")
    
    # 6.2 ä¿å­˜æ–‡æœ¬ç»“æœï¼ˆåŒ…å«é…ç½®ï¼‰
    results_file = results_dir / 'cifar10_experiment_results.txt'
    with open(results_file, 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "")
        f.write("CIFAR-10 Softmaxåˆ†ç±»å™¨å®éªŒç»“æœ")
        f.write("=" * 70 + "")
        
        # ä¿å­˜é…ç½®
        f.write("å®éªŒé…ç½®:")
        f.write("-" * 70 + "")
        f.write("æ•°æ®é›†:")
        for key, value in CONFIG['data'].items():
            f.write(f"  {key}: {value}")
        f.write("æ¨¡å‹:")
        for key, value in CONFIG['model'].items():
            f.write(f"  {key}: {value}")
        f.write("è®­ç»ƒ:")
        for key, value in CONFIG['training'].items():
            f.write(f"  {key}: {value}")
        f.write("" + "-" * 70 + "")
        
        f.write("æ•°æ®é›†ä¿¡æ¯:")
        f.write(f"  è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        f.write(f"  éªŒè¯é›†: {len(X_val)} æ ·æœ¬")
        f.write(f"  æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        f.write(f"  ç‰¹å¾ç»´åº¦: {X_train.shape[1]}")
        
        f.write("æœ€ç»ˆæ€§èƒ½:")
        f.write(f"  è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f} ({train_acc*100:.2f}%)")
        f.write(f"  éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f} ({val_acc*100:.2f}%)")
        f.write(f"  æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f} ({test_acc*100:.2f}%)")
        
        f.write("è®­ç»ƒå†å²:")
        f.write("-" * 70 + "")
        f.write(f"{'Epoch':<10}{'Loss':<15}{'Train Acc':<15}{'Val Acc':<15}")
        f.write("-" * 70 + "")
        for i, epoch in enumerate(history['epochs']):
            f.write(f"{epoch:<10}{history['loss_history'][epoch]:<15.4f}"
                   f"{history['train_acc_history'][i]:<15.4f}"
                   f"{history['val_acc_history'][i]:<15.4f}")
        
        f.write("" + "=" * 70 + "")
    
    print(f"âœ“ æ–‡æœ¬ç»“æœå·²ä¿å­˜: {results_file.name}")
    
    # 6.3 ç”Ÿæˆå¯è§†åŒ–
    print("ç”Ÿæˆå¯è§†åŒ–...")
    print("-" * 70)
    
    curves_path = results_dir / 'training_curves.png'
    plot_training_curves(history, curves_path)
    
    weights_path = results_dir / 'weight_visualization.png'
    class_names = get_cifar10_class_names()
    visualize_weights(classifier.W, class_names, weights_path)
    
    pred_path = results_dir / 'cifar10_prediction_visualization.png'
    visualize_predictions(
        X_test, y_test, classifier, class_names, pred_path,
        num_samples=CONFIG['visualization']['num_pred_samples']
    )
    
    # ==================== å®Œæˆ ====================
    print("" + "=" * 70)
    print("âœ… å®éªŒå®Œæˆï¼")
    print("=" * 70)
    print(f"ğŸ“Š æœ€ç»ˆç»“æœ:")
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f} ({test_acc*100:.2f}%)")
    print(f"ğŸ“ ç»“æœæ–‡ä»¶ä½ç½®:")
    print(f"   {results_dir}/")
    print(f"   â”œâ”€â”€ cifar10_experiment_results.txt")
    print(f"   â”œâ”€â”€ training_curves.png")
    print(f"   â”œâ”€â”€ weight_visualization.png")
    print(f"   â”œâ”€â”€ cifar10_prediction_visualization.png")
    print(f"   â””â”€â”€ softmax_classifier.npy")
    print("=" * 70)


if __name__ == '__main__':
    main()
